{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook of our final approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#to read/write csv\n",
    "import pandas as pd\n",
    "\n",
    "#for SVM\n",
    "from SVM import fit_SVM_and_predict\n",
    "\n",
    "#for other features\n",
    "from tqdm import tqdm\n",
    "from kernels import phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.7 # We will take 90% on data for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and standardize features by removing the mean and scaling to unit variance\n",
    "StandardScaler = lambda df: (df-df.mean())/df.std()\n",
    "\n",
    "XTrain0 = pd.read_csv('./data/Xtr0_mat100.csv', sep=' ', header=None)\n",
    "XTrain1 = pd.read_csv('./data/Xtr1_mat100.csv', sep=' ', header=None)\n",
    "XTrain2 = pd.read_csv('./data/Xtr2_mat100.csv', sep=' ', header=None)\n",
    "\n",
    "# Standardize the Test features using the mean and std of the TRAIN features\n",
    "XTest0 = (pd.read_csv('./data/Xte0_mat100.csv', sep=' ', header=None)-XTrain0.mean())/XTrain0.std()\n",
    "XTest1 = (pd.read_csv('./data/Xte1_mat100.csv', sep=' ', header=None)-XTrain1.mean())/XTrain1.std()\n",
    "XTest2 = (pd.read_csv('./data/Xte2_mat100.csv', sep=' ', header=None)-XTrain2.mean())/XTrain2.std()\n",
    "\n",
    "YTrain0 = pd.read_csv('./data/Ytr0.csv', usecols = ['Bound'])\n",
    "YTrain1 = pd.read_csv('./data/Ytr1.csv', usecols = ['Bound'])\n",
    "YTrain2 = pd.read_csv('./data/Ytr2.csv', usecols = ['Bound'])\n",
    "\n",
    "XTrain0_ATGC = pd.read_csv('./data/Xtr0.csv', sep=' ', header=None)\n",
    "XTrain1_ATGC = pd.read_csv('./data/Xtr1.csv', sep=' ', header=None)\n",
    "XTrain2_ATGC = pd.read_csv('./data/Xtr2.csv', sep=' ', header=None)\n",
    "\n",
    "XTest0_ATGC = pd.read_csv('./data/Xte0.csv', sep=' ', header=None)\n",
    "XTest1_ATGC = pd.read_csv('./data/Xte1.csv', sep=' ', header=None)\n",
    "XTest2_ATGC = pd.read_csv('./data/Xte2.csv', sep=' ', header=None)\n",
    "\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0 = StandardScaler(XTrain0)\n",
    "XTrain1 = StandardScaler(XTrain1)\n",
    "XTrain2 = StandardScaler(XTrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features with our own kernel from raw sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of features:65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "k=8 #length of subsequences considered\n",
    "\n",
    "print('dimension of features:{}'.format(4**k))\n",
    "XTrain0KF=np.zeros([len(XTrain0_ATGC)-1,4**k]) \n",
    "XTrain1KF=np.zeros([len(XTrain1_ATGC)-1,4**k])\n",
    "XTrain2KF=np.zeros([len(XTrain2_ATGC)-1,4**k])\n",
    "\n",
    "XTest0KF=np.zeros([len(XTest0_ATGC)-1,4**k])\n",
    "XTest1KF=np.zeros([len(XTest1_ATGC)-1,4**k])\n",
    "XTest2KF=np.zeros([len(XTest2_ATGC)-1,4**k])\n",
    "\n",
    "ATGC=[XTrain0_ATGC,XTrain1_ATGC,XTrain2_ATGC,XTest0_ATGC,XTest1_ATGC,XTest2_ATGC]\n",
    "KF=[XTrain0KF,XTrain1KF,XTrain2KF,XTest0KF,XTest1KF,XTest2KF]  #KF stands for kernel_features\n",
    "\n",
    "for data in tqdm(range(6)):\n",
    "    for idx,sequence in enumerate(ATGC[data][0][1:]): #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "        x = sequence.split(',')[1]\n",
    "        KF[data][idx,:]=phi(x,k,kernel='spectrum_efficient')\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0KF = StandardScaler(XTrain0KF)\n",
    "XTrain1KF = StandardScaler(XTrain1KF)\n",
    "XTrain2KF = StandardScaler(XTrain2KF)\n",
    "\n",
    "\n",
    "XTest0KF = XTest0KF-XTrain0KF.mean()/XTrain0KF.std()\n",
    "XTest1KF = XTest1KF-XTrain1KF.mean()/XTrain1KF.std()\n",
    "XTest2KF = XTest2KF-XTrain2KF.mean()/XTrain2KF.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.33% accuracy on dataset 0 for lambda = 1e-08\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-08\n",
      "70.00% accuracy on dataset 2 for lambda = 1e-08\n",
      "--------------------------------------------\n",
      "60.67% accuracy on dataset 0 for lambda = 1e-07\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-07\n",
      "70.50% accuracy on dataset 2 for lambda = 1e-07\n",
      "--------------------------------------------\n",
      "61.33% accuracy on dataset 0 for lambda = 1e-06\n",
      "58.50% accuracy on dataset 1 for lambda = 1e-06\n",
      "70.50% accuracy on dataset 2 for lambda = 1e-06\n",
      "--------------------------------------------\n",
      "61.17% accuracy on dataset 0 for lambda = 5e-06\n",
      "58.17% accuracy on dataset 1 for lambda = 5e-06\n",
      "72.33% accuracy on dataset 2 for lambda = 5e-06\n",
      "--------------------------------------------\n",
      "62.00% accuracy on dataset 0 for lambda = 8e-06\n",
      "58.33% accuracy on dataset 1 for lambda = 8e-06\n",
      "73.17% accuracy on dataset 2 for lambda = 8e-06\n",
      "--------------------------------------------\n",
      "62.50% accuracy on dataset 0 for lambda = 9e-06\n",
      "58.50% accuracy on dataset 1 for lambda = 9e-06\n",
      "72.17% accuracy on dataset 2 for lambda = 9e-06\n",
      "--------------------------------------------\n",
      "62.67% accuracy on dataset 0 for lambda = 1e-05\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-05\n",
      "72.00% accuracy on dataset 2 for lambda = 1e-05\n",
      "--------------------------------------------\n",
      "60.67% accuracy on dataset 0 for lambda = 2e-05\n",
      "57.67% accuracy on dataset 1 for lambda = 2e-05\n",
      "71.83% accuracy on dataset 2 for lambda = 2e-05\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 5e-05\n",
      "57.50% accuracy on dataset 1 for lambda = 5e-05\n",
      "72.00% accuracy on dataset 2 for lambda = 5e-05\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 0.0001\n",
      "57.50% accuracy on dataset 1 for lambda = 0.0001\n",
      "71.67% accuracy on dataset 2 for lambda = 0.0001\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 0.001\n",
      "57.50% accuracy on dataset 1 for lambda = 0.001\n",
      "71.33% accuracy on dataset 2 for lambda = 0.001\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_lambda=1\n",
    "best_accuracy=0\n",
    "\n",
    "for lambdaa in [1e-8,1e-7,1e-6,5e-6,8e-6,9e-6,1e-5,2e-5,5e-5,1e-4,1e-3]:\n",
    "\n",
    "    K0 = np.dot(XTrain0KF[:int(len(XTrain0)*split)],XTrain0KF[:int(len(XTrain0)*split)].T) \n",
    "    G0 = np.dot(XTrain0KF[int(len(XTrain0)*split):], XTrain0KF[:int(len(XTrain0)*split)].T)\n",
    "    Y0 = np.squeeze(np.array(YTrain0[:int(len(XTrain0)*split)]))\n",
    "    \n",
    "    K1 = np.dot(XTrain1KF[:int(len(XTrain1)*split)],XTrain1KF[:int(len(XTrain1)*split)].T) \n",
    "    G1 = np.dot(XTrain1KF[int(len(XTrain1)*split):], XTrain1KF[:int(len(XTrain1)*split)].T)\n",
    "    Y1 = np.squeeze(np.array(YTrain1[:int(len(XTrain1)*split)]))\n",
    "    \n",
    "    K2 = np.dot(XTrain2KF[:int(len(XTrain0)*split)],XTrain2KF[:int(len(XTrain2)*split)].T) \n",
    "    G2 = np.dot(XTrain2KF[int(len(XTrain2)*split):], XTrain2KF[:int(len(XTrain2)*split)].T)\n",
    "    Y2 = np.squeeze(np.array(YTrain2[:int(len(XTrain2)*split)]))\n",
    "    \n",
    "    #Predictions -1/1\n",
    "    p0=fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=lambdaa,get_proba=False)\n",
    "    p1=fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=lambdaa,get_proba=False)\n",
    "    p2=fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=lambdaa,get_proba=False)\n",
    "    \n",
    "    #Predictions 0/1\n",
    "    predictions0 = (1+np.sign(p0))/2\n",
    "    predictions1 = (1+np.sign(p1))/2\n",
    "    predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "    #Asses the predictions\n",
    "    y_true0 = np.array(YTrain0['Bound'][int(len(XTrain0)*split):])\n",
    "    y_true1 = np.array(YTrain1['Bound'][int(len(XTrain1)*split):])\n",
    "    y_true2 = np.array(YTrain2['Bound'][int(len(XTrain2)*split):])\n",
    "    \n",
    "    #Compute the accuracy\n",
    "    accuracy0=100*(1-np.mean(abs(y_true0-predictions0)))\n",
    "    accuracy1=100*(1-np.mean(abs(y_true1-predictions1)))\n",
    "    accuracy2=100*(1-np.mean(abs(y_true2-predictions2)))\n",
    "    accuracy=(accuracy0+accuracy1+accuracy2)/3\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_lambda=lambdaa\n",
    "\n",
    "    print(\"{:.2f}% accuracy on dataset 0 for lambda = {}\".format(accuracy0,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 1 for lambda = {}\".format(accuracy1,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 2 for lambda = {}\".format(accuracy2,lambdaa))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate csv file to upload on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset 0\n",
    "K0 = np.dot(XTrain0KF,XTrain0KF.T)  \n",
    "G0 = np.dot(XTest0KF, XTrain0KF.T)\n",
    "Y0 = np.squeeze(np.array(YTrain0))\n",
    "p0 = fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=best_lambda,get_proba=False)\n",
    "\n",
    "#Dataset 1\n",
    "K1 = np.dot(XTrain1KF,XTrain1KF.T)  \n",
    "G1 = np.dot(XTest1KF, XTrain1KF.T)\n",
    "Y1 = np.squeeze(np.array(YTrain1))\n",
    "p1 = fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=best_lambda,get_proba=False)\n",
    "\n",
    "#Dataset 2\n",
    "K2 = np.dot(XTrain2KF,XTrain2KF.T)  \n",
    "G2 = np.dot(XTest2KF, XTrain2KF.T)\n",
    "Y2 = np.squeeze(np.array(YTrain2))\n",
    "p2 = fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=best_lambda,get_proba=False)\n",
    "\n",
    "\n",
    "#Predictions 0/1\n",
    "predictions0 = (1+np.sign(p0))/2\n",
    "predictions1 = (1+np.sign(p1))/2\n",
    "predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "# Creation of the Kaggle submission file\n",
    "df0 = pd.DataFrame({'Id': np.arange(1000), 'Bound': predictions0.squeeze().astype(int)})\n",
    "df1 = pd.DataFrame({'Id': np.arange(1000,2000), 'Bound': predictions1.squeeze().astype(int)})\n",
    "df2 = pd.DataFrame({'Id': np.arange(2000,3000), 'Bound': predictions2.squeeze().astype(int)})\n",
    "dfResult = pd.concat([df0,df1,df2])\n",
    "dfResult.to_csv('./data/submissionSVM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
