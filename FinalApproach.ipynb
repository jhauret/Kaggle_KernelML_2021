{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook of our final approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#to read/write csv\n",
    "import pandas as pd\n",
    "\n",
    "#for SVM\n",
    "from SVM import fit_SVM_and_predict\n",
    "\n",
    "#for other features\n",
    "from tqdm import tqdm\n",
    "from kernels import phi,K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.7 # We will take 90% on data for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and standardize features by removing the mean and scaling to unit variance\n",
    "StandardScaler = lambda df: (df-df.mean())/df.std()\n",
    "\n",
    "XTrain0 = pd.read_csv('./data/Xtr0_mat100.csv', sep=' ', header=None)\n",
    "XTrain1 = pd.read_csv('./data/Xtr1_mat100.csv', sep=' ', header=None)\n",
    "XTrain2 = pd.read_csv('./data/Xtr2_mat100.csv', sep=' ', header=None)\n",
    "\n",
    "# Standardize the Test features using the mean and std of the TRAIN features\n",
    "XTest0 = (pd.read_csv('./data/Xte0_mat100.csv', sep=' ', header=None)-XTrain0.mean())/XTrain0.std()\n",
    "XTest1 = (pd.read_csv('./data/Xte1_mat100.csv', sep=' ', header=None)-XTrain1.mean())/XTrain1.std()\n",
    "XTest2 = (pd.read_csv('./data/Xte2_mat100.csv', sep=' ', header=None)-XTrain2.mean())/XTrain2.std()\n",
    "\n",
    "YTrain0 = pd.read_csv('./data/Ytr0.csv', usecols = ['Bound'])\n",
    "YTrain1 = pd.read_csv('./data/Ytr1.csv', usecols = ['Bound'])\n",
    "YTrain2 = pd.read_csv('./data/Ytr2.csv', usecols = ['Bound'])\n",
    "\n",
    "XTrain0_ATGC = pd.read_csv('./data/Xtr0.csv', sep=' ', header=None)\n",
    "XTrain1_ATGC = pd.read_csv('./data/Xtr1.csv', sep=' ', header=None)\n",
    "XTrain2_ATGC = pd.read_csv('./data/Xtr2.csv', sep=' ', header=None)\n",
    "\n",
    "XTest0_ATGC = pd.read_csv('./data/Xte0.csv', sep=' ', header=None)\n",
    "XTest1_ATGC = pd.read_csv('./data/Xte1.csv', sep=' ', header=None)\n",
    "XTest2_ATGC = pd.read_csv('./data/Xte2.csv', sep=' ', header=None)\n",
    "\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0 = StandardScaler(XTrain0)\n",
    "XTrain1 = StandardScaler(XTrain1)\n",
    "XTrain2 = StandardScaler(XTrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectruc Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of features:65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "#                                           SPECTRUM KERNEL                                       #\n",
    "###################################################################################################\n",
    "k=8 #length of subsequences considered\n",
    "\n",
    "print('dimension of features:{}'.format(4**k))\n",
    "XTrain0KF=np.zeros([len(XTrain0_ATGC)-1,4**k]) \n",
    "XTrain1KF=np.zeros([len(XTrain1_ATGC)-1,4**k])\n",
    "XTrain2KF=np.zeros([len(XTrain2_ATGC)-1,4**k])\n",
    "\n",
    "XTest0KF=np.zeros([len(XTest0_ATGC)-1,4**k])\n",
    "XTest1KF=np.zeros([len(XTest1_ATGC)-1,4**k])\n",
    "XTest2KF=np.zeros([len(XTest2_ATGC)-1,4**k])\n",
    "\n",
    "ATGC=[XTrain0_ATGC,XTrain1_ATGC,XTrain2_ATGC,XTest0_ATGC,XTest1_ATGC,XTest2_ATGC]\n",
    "KF=[XTrain0KF,XTrain1KF,XTrain2KF,XTest0KF,XTest1KF,XTest2KF]  #KF stands for kernel_features\n",
    "\n",
    "for data in tqdm(range(6)):\n",
    "    for idx,sequence in enumerate(ATGC[data][0][1:]): #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "        x = sequence.split(',')[1]\n",
    "        KF[data][idx,:]=phi(x,k,kernel='spectrum_efficient')\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0KF = StandardScaler(XTrain0KF)\n",
    "XTrain1KF = StandardScaler(XTrain1KF)\n",
    "XTrain2KF = StandardScaler(XTrain2KF)\n",
    "\n",
    "\n",
    "XTest0KF = XTest0KF-XTrain0KF.mean()/XTrain0KF.std()\n",
    "XTest1KF = XTest1KF-XTrain1KF.mean()/XTrain1KF.std()\n",
    "XTest2KF = XTest2KF-XTrain2KF.mean()/XTrain2KF.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.33% accuracy on dataset 0 for lambda = 1e-08\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-08\n",
      "70.00% accuracy on dataset 2 for lambda = 1e-08\n",
      "--------------------------------------------\n",
      "60.67% accuracy on dataset 0 for lambda = 1e-07\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-07\n",
      "70.50% accuracy on dataset 2 for lambda = 1e-07\n",
      "--------------------------------------------\n",
      "61.33% accuracy on dataset 0 for lambda = 1e-06\n",
      "58.50% accuracy on dataset 1 for lambda = 1e-06\n",
      "70.50% accuracy on dataset 2 for lambda = 1e-06\n",
      "--------------------------------------------\n",
      "61.17% accuracy on dataset 0 for lambda = 5e-06\n",
      "58.17% accuracy on dataset 1 for lambda = 5e-06\n",
      "72.33% accuracy on dataset 2 for lambda = 5e-06\n",
      "--------------------------------------------\n",
      "62.00% accuracy on dataset 0 for lambda = 8e-06\n",
      "58.33% accuracy on dataset 1 for lambda = 8e-06\n",
      "73.17% accuracy on dataset 2 for lambda = 8e-06\n",
      "--------------------------------------------\n",
      "62.50% accuracy on dataset 0 for lambda = 9e-06\n",
      "58.50% accuracy on dataset 1 for lambda = 9e-06\n",
      "72.17% accuracy on dataset 2 for lambda = 9e-06\n",
      "--------------------------------------------\n",
      "62.67% accuracy on dataset 0 for lambda = 1e-05\n",
      "58.17% accuracy on dataset 1 for lambda = 1e-05\n",
      "72.00% accuracy on dataset 2 for lambda = 1e-05\n",
      "--------------------------------------------\n",
      "60.67% accuracy on dataset 0 for lambda = 2e-05\n",
      "57.67% accuracy on dataset 1 for lambda = 2e-05\n",
      "71.83% accuracy on dataset 2 for lambda = 2e-05\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 5e-05\n",
      "57.50% accuracy on dataset 1 for lambda = 5e-05\n",
      "72.00% accuracy on dataset 2 for lambda = 5e-05\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 0.0001\n",
      "57.50% accuracy on dataset 1 for lambda = 0.0001\n",
      "71.67% accuracy on dataset 2 for lambda = 0.0001\n",
      "--------------------------------------------\n",
      "60.50% accuracy on dataset 0 for lambda = 0.001\n",
      "57.50% accuracy on dataset 1 for lambda = 0.001\n",
      "71.33% accuracy on dataset 2 for lambda = 0.001\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_lambda=1\n",
    "best_accuracy=0\n",
    "\n",
    "for lambdaa in [1e-8,1e-7,1e-6,5e-6,8e-6,9e-6,1e-5,2e-5,5e-5,1e-4,1e-3]:\n",
    "\n",
    "    K0 = np.dot(XTrain0KF[:int(len(XTrain0)*split)],XTrain0KF[:int(len(XTrain0)*split)].T) \n",
    "    G0 = np.dot(XTrain0KF[int(len(XTrain0)*split):], XTrain0KF[:int(len(XTrain0)*split)].T)\n",
    "    Y0 = np.squeeze(np.array(YTrain0[:int(len(XTrain0)*split)]))\n",
    "    \n",
    "    K1 = np.dot(XTrain1KF[:int(len(XTrain1)*split)],XTrain1KF[:int(len(XTrain1)*split)].T) \n",
    "    G1 = np.dot(XTrain1KF[int(len(XTrain1)*split):], XTrain1KF[:int(len(XTrain1)*split)].T)\n",
    "    Y1 = np.squeeze(np.array(YTrain1[:int(len(XTrain1)*split)]))\n",
    "    \n",
    "    K2 = np.dot(XTrain2KF[:int(len(XTrain0)*split)],XTrain2KF[:int(len(XTrain2)*split)].T) \n",
    "    G2 = np.dot(XTrain2KF[int(len(XTrain2)*split):], XTrain2KF[:int(len(XTrain2)*split)].T)\n",
    "    Y2 = np.squeeze(np.array(YTrain2[:int(len(XTrain2)*split)]))\n",
    "    \n",
    "    #Predictions -1/1\n",
    "    p0=fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=lambdaa,get_proba=False)\n",
    "    p1=fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=lambdaa,get_proba=False)\n",
    "    p2=fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=lambdaa,get_proba=False)\n",
    "    \n",
    "    #Predictions 0/1\n",
    "    predictions0 = (1+np.sign(p0))/2\n",
    "    predictions1 = (1+np.sign(p1))/2\n",
    "    predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "    #Asses the predictions\n",
    "    y_true0 = np.array(YTrain0['Bound'][int(len(XTrain0)*split):])\n",
    "    y_true1 = np.array(YTrain1['Bound'][int(len(XTrain1)*split):])\n",
    "    y_true2 = np.array(YTrain2['Bound'][int(len(XTrain2)*split):])\n",
    "    \n",
    "    #Compute the accuracy\n",
    "    accuracy0=100*(1-np.mean(abs(y_true0-predictions0)))\n",
    "    accuracy1=100*(1-np.mean(abs(y_true1-predictions1)))\n",
    "    accuracy2=100*(1-np.mean(abs(y_true2-predictions2)))\n",
    "    accuracy=(accuracy0+accuracy1+accuracy2)/3\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_lambda=lambdaa\n",
    "\n",
    "    print(\"{:.2f}% accuracy on dataset 0 for lambda = {}\".format(accuracy0,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 1 for lambda = {}\".format(accuracy1,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 2 for lambda = {}\".format(accuracy2,lambdaa))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate csv file to upload on Kaggle for spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset 0\n",
    "K0 = np.dot(XTrain0KF,XTrain0KF.T)  \n",
    "G0 = np.dot(XTest0KF, XTrain0KF.T)\n",
    "Y0 = np.squeeze(np.array(YTrain0))\n",
    "p0 = fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=best_lambda,get_proba=False)\n",
    "\n",
    "#Dataset 1\n",
    "K1 = np.dot(XTrain1KF,XTrain1KF.T)  \n",
    "G1 = np.dot(XTest1KF, XTrain1KF.T)\n",
    "Y1 = np.squeeze(np.array(YTrain1))\n",
    "p1 = fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=best_lambda,get_proba=False)\n",
    "\n",
    "#Dataset 2\n",
    "K2 = np.dot(XTrain2KF,XTrain2KF.T)  \n",
    "G2 = np.dot(XTest2KF, XTrain2KF.T)\n",
    "Y2 = np.squeeze(np.array(YTrain2))\n",
    "p2 = fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=best_lambda,get_proba=False)\n",
    "\n",
    "\n",
    "#Predictions 0/1\n",
    "predictions0 = (1+np.sign(p0))/2\n",
    "predictions1 = (1+np.sign(p1))/2\n",
    "predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "# Creation of the Kaggle submission file\n",
    "df0 = pd.DataFrame({'Id': np.arange(1000), 'Bound': predictions0.squeeze().astype(int)})\n",
    "df1 = pd.DataFrame({'Id': np.arange(1000,2000), 'Bound': predictions1.squeeze().astype(int)})\n",
    "df2 = pd.DataFrame({'Id': np.arange(2000,3000), 'Bound': predictions2.squeeze().astype(int)})\n",
    "dfResult = pd.concat([df0,df1,df2])\n",
    "dfResult.to_csv('./data/submissionSVM.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL ALIGNMENT KERNEL with BIOPYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions (the mapping $\\phi$ is not explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#                                    GLOBAL ALIGNMENT KERNEL                                      #\n",
    "###################################################################################################\n",
    "def construct_KERNELmat(XATGC):\n",
    "    XATGC=XATGC[0][1:] #[0] pour première colone #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "    Kmat=np.zeros([len(XATGC),len(XATGC)])\n",
    "    \n",
    "    for idx1,sequence1 in enumerate(XATGC):\n",
    "        x1 = sequence1.split(',')[1]\n",
    "        for idx2,sequence2 in enumerate(XATGC):\n",
    "            x2 = sequence2.split(',')[1]\n",
    "            if idx1>=idx2:#because the matrice is symmetric for kernel matrices\n",
    "                Kmat[idx1,idx2]=K(x1,x2,kernel='bio')\n",
    "                Kmat[idx2,idx1]=Kmat[idx1,idx2]\n",
    "    \n",
    "    return Kmat\n",
    "\n",
    "def construct_Grammat(XTrainATGC,XTestATGC):\n",
    "    \n",
    "    XTestATGC=XTestATGC[0][1:] #[0] pour première colone #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "    XTrainATGC=XTrainATGC[0][1:] #[0] pour première colone #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "    Gmat=np.zeros([len(XTestATGC),len(XTrainATGC)])\n",
    "    \n",
    "    for idx1,sequence1 in enumerate(XTestATGC):\n",
    "        x1 = sequence1.split(',')[1]\n",
    "        for idx2,sequence2 in enumerate(XTrainATGC):\n",
    "            x2 = sequence2.split(',')[1]\n",
    "            Gmat[idx1,idx2]=K(x1,x2,kernel='bio')\n",
    "    \n",
    "    return Gmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K0 constructed\n",
      "K1 constructed\n",
      "K2 constructed\n",
      "G0 constructed\n",
      "G1 constructed\n",
      "G2 constructed\n"
     ]
    }
   ],
   "source": [
    "# construct validation matrices\n",
    "\n",
    "K0=construct_KERNELmat(XTrain0_ATGC[:int(len(XTrain0)*split)+1]) #takes 3min\n",
    "print('K0 constructed')\n",
    "K1=construct_KERNELmat(XTrain1_ATGC[:int(len(XTrain1)*split)+1]) #takes 3min\n",
    "print('K1 constructed')\n",
    "K2=construct_KERNELmat(XTrain2_ATGC[:int(len(XTrain2)*split)+1]) #takes 3min\n",
    "print('K2 constructed')\n",
    "G0=construct_Grammat(XTrain0_ATGC[:int(len(XTrain0)*split)+1],XTrain0_ATGC[int(len(XTrain0)*split):]) \n",
    "print('G0 constructed')\n",
    "G1=construct_Grammat(XTrain1_ATGC[:int(len(XTrain1)*split)+1],XTrain1_ATGC[int(len(XTrain1)*split):]) \n",
    "print('G1 constructed')\n",
    "G2=construct_Grammat(XTrain2_ATGC[:int(len(XTrain2)*split)+1],XTrain2_ATGC[int(len(XTrain2)*split):])\n",
    "print('G2 constructed')\n",
    "\n",
    "\n",
    "Y0 = np.squeeze(np.array(YTrain0[:int(len(XTrain0)*split)]))\n",
    "Y1 = np.squeeze(np.array(YTrain1[:int(len(XTrain1)*split)]))\n",
    "Y2 = np.squeeze(np.array(YTrain2[:int(len(XTrain2)*split)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank(A) < p or Rank([P; A; G]) < n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                     \u001b[0mlapack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArithmeticError\u001b[0m: 171",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArithmeticError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rti'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m   1980\u001b[0m          \u001b[0;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                     \u001b[0mlapack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArithmeticError\u001b[0m: 171",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f684c14ddba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Predictions -1/1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mp0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_SVM_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdaa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mp1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_SVM_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdaa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mp2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_SVM_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdaa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/ENS/MVA/Semestre 2/Kernel_methods/Kaggle_KernelML_2021/SVM.py\u001b[0m in \u001b[0;36mfit_SVM_and_predict\u001b[0;34m(K, gram, Y, C, get_proba)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# TODO : implement the intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/ENS/MVA/Semestre 2/Kernel_methods/Kaggle_KernelML_2021/SVM.py\u001b[0m in \u001b[0;36mSVM\u001b[0;34m(K, Y, C)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4483\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rank(A) < p or Rank([P; A; G]) < n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Rank(A) < p or Rank([P; A; G]) < n"
     ]
    }
   ],
   "source": [
    "#look for the best regularization parameter\n",
    "best_lambda=1\n",
    "best_accuracy=0\n",
    "\n",
    "for lambdaa in [1e-8,1e-7,1e-6,5e-6,8e-6,9e-6,1e-5,2e-5,5e-5,1e-4,1e-3]:\n",
    "    \n",
    "    #Predictions -1/1\n",
    "    p0=fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=lambdaa,get_proba=False)\n",
    "    p1=fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=lambdaa,get_proba=False)\n",
    "    p2=fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=lambdaa,get_proba=False)\n",
    "    \n",
    "    #Predictions 0/1\n",
    "    predictions0 = (1+np.sign(p0))/2\n",
    "    predictions1 = (1+np.sign(p1))/2\n",
    "    predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "    #Asses the predictions\n",
    "    y_true0 = np.array(YTrain0['Bound'][int(len(XTrain0)*split):])\n",
    "    y_true1 = np.array(YTrain1['Bound'][int(len(XTrain1)*split):])\n",
    "    y_true2 = np.array(YTrain2['Bound'][int(len(XTrain2)*split):])\n",
    "    \n",
    "    #Compute the accuracy\n",
    "    accuracy0=100*(1-np.mean(abs(y_true0-predictions0)))\n",
    "    accuracy1=100*(1-np.mean(abs(y_true1-predictions1)))\n",
    "    accuracy2=100*(1-np.mean(abs(y_true2-predictions2)))\n",
    "    accuracy=(accuracy0+accuracy1+accuracy2)/3\n",
    "    \n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_lambda=lambdaa\n",
    "\n",
    "    print(\"{:.2f}% accuracy on dataset 0 for lambda = {}\".format(accuracy0,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 1 for lambda = {}\".format(accuracy1,lambdaa))\n",
    "    print(\"{:.2f}% accuracy on dataset 2 for lambda = {}\".format(accuracy2,lambdaa))\n",
    "    print(\"--------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate csv file to upload on Kaggle for GLOBAL ALIGNMENT kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-467368658e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mK0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstruct_KERNELmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain0_ATGC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#takes 3min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K0 constructed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mK1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstruct_KERNELmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain1_ATGC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#takes 3min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-467368658e59>\u001b[0m in \u001b[0;36mconstruct_KERNELmat\u001b[0;34m(XATGC)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx1\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#because the matrice is symmetric for kernel matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mKmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mKmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/ENS/MVA/Semestre 2/Kernel_methods/Kaggle_KernelML_2021/kernels.py\u001b[0m in \u001b[0;36mK\u001b[0;34m(seq1, seq2, k, tolerance, kernel)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'bio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalxx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Bio/pairwise2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **keywds)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;34m\"\"\"Call the alignment instance already created.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mkeywds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkeywds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Bio/pairwise2.py\u001b[0m in \u001b[0;36m_align\u001b[0;34m(sequenceA, sequenceB, match_fn, gap_A_fn, gap_B_fn, penalize_extend_when_opening, penalize_end_gaps, align_globally, gap_char, force_generic, score_only, one_alignment_only)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mpenalize_end_gaps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0malign_globally\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mscore_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         )\n\u001b[1;32m    573\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K0=construct_KERNELmat(XTrain0_ATGC) #takes 3min\n",
    "print('K0 constructed')\n",
    "K1=construct_KERNELmat(XTrain1_ATGC) #takes 3min\n",
    "print('K1 constructed')\n",
    "K2=construct_KERNELmat(XTrain2_ATGC) #takes 3min\n",
    "print('K2 constructed')\n",
    "G0=construct_KERNELmat(XTrain0_ATGC,XTest0_ATGC) \n",
    "print('G0 constructed')\n",
    "G1=construct_KERNELmat(XTrain1_ATGC,XTest1_ATGC) \n",
    "print('G1 constructed')\n",
    "G2=construct_KERNELmat(XTrain2_ATGC,XTest2_ATGC)\n",
    "print('G2 constructed')\n",
    "\n",
    "\n",
    "Y0 = np.squeeze(np.array(YTrain0))\n",
    "p0 = fit_SVM_and_predict(K=K0,gram=G0,Y=Y0,C=best_lambda,get_proba=False)\n",
    "\n",
    "Y1 = np.squeeze(np.array(YTrain1))\n",
    "p1 = fit_SVM_and_predict(K=K1,gram=G1,Y=Y1,C=best_lambda,get_proba=False)\n",
    "\n",
    "\n",
    "Y2 = np.squeeze(np.array(YTrain2))\n",
    "p2 = fit_SVM_and_predict(K=K2,gram=G2,Y=Y2,C=best_lambda,get_proba=False)\n",
    "\n",
    "\n",
    "#Predictions 0/1\n",
    "predictions0 = (1+np.sign(p0))/2\n",
    "predictions1 = (1+np.sign(p1))/2\n",
    "predictions2 = (1+np.sign(p2))/2\n",
    "\n",
    "# Creation of the Kaggle submission file\n",
    "df0 = pd.DataFrame({'Id': np.arange(1000), 'Bound': predictions0.squeeze().astype(int)})\n",
    "df1 = pd.DataFrame({'Id': np.arange(1000,2000), 'Bound': predictions1.squeeze().astype(int)})\n",
    "df2 = pd.DataFrame({'Id': np.arange(2000,3000), 'Bound': predictions2.squeeze().astype(int)})\n",
    "dfResult = pd.concat([df0,df1,df2])\n",
    "dfResult.to_csv('./data/submissionSVM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
