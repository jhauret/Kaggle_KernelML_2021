{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook of our final approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#to read/write csv\n",
    "import pandas as pd\n",
    "\n",
    "#for SVM\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "\n",
    "#for other features\n",
    "from tqdm import tqdm\n",
    "from kernels import phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=0.7 # We will take 90% on data for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and standardize features by removing the mean and scaling to unit variance\n",
    "StandardScaler = lambda df: (df-df.mean())/df.std()\n",
    "\n",
    "XTrain0 = pd.read_csv('./data/Xtr0_mat100.csv', sep=' ', header=None)\n",
    "XTrain1 = pd.read_csv('./data/Xtr1_mat100.csv', sep=' ', header=None)\n",
    "XTrain2 = pd.read_csv('./data/Xtr2_mat100.csv', sep=' ', header=None)\n",
    "\n",
    "# Standardize the Test features using the mean and std of the TRAIN features\n",
    "XTest0 = (pd.read_csv('./data/Xte0_mat100.csv', sep=' ', header=None)-XTrain0.mean())/XTrain0.std()\n",
    "XTest1 = (pd.read_csv('./data/Xte1_mat100.csv', sep=' ', header=None)-XTrain1.mean())/XTrain1.std()\n",
    "XTest2 = (pd.read_csv('./data/Xte2_mat100.csv', sep=' ', header=None)-XTrain2.mean())/XTrain2.std()\n",
    "\n",
    "YTrain0 = pd.read_csv('./data/Ytr0.csv', usecols = ['Bound'])\n",
    "YTrain1 = pd.read_csv('./data/Ytr1.csv', usecols = ['Bound'])\n",
    "YTrain2 = pd.read_csv('./data/Ytr2.csv', usecols = ['Bound'])\n",
    "\n",
    "XTrain0_ATGC = pd.read_csv('./data/Xtr0.csv', sep=' ', header=None)\n",
    "XTrain1_ATGC = pd.read_csv('./data/Xtr1.csv', sep=' ', header=None)\n",
    "XTrain2_ATGC = pd.read_csv('./data/Xtr2.csv', sep=' ', header=None)\n",
    "\n",
    "XTest0_ATGC = pd.read_csv('./data/Xte0.csv', sep=' ', header=None)\n",
    "XTest1_ATGC = pd.read_csv('./data/Xte1.csv', sep=' ', header=None)\n",
    "XTest2_ATGC = pd.read_csv('./data/Xte2.csv', sep=' ', header=None)\n",
    "\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0 = StandardScaler(XTrain0)\n",
    "XTrain1 = StandardScaler(XTrain1)\n",
    "XTrain2 = StandardScaler(XTrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features with our own kernel from raw sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of features:65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "k=8 #length of subsequences considered\n",
    "\n",
    "print('dimension of features:{}'.format(4**k))\n",
    "XTrain0KF=np.zeros([len(XTrain0_ATGC)-1,4**k]) \n",
    "XTrain1KF=np.zeros([len(XTrain1_ATGC)-1,4**k])\n",
    "XTrain2KF=np.zeros([len(XTrain2_ATGC)-1,4**k])\n",
    "\n",
    "XTest0KF=np.zeros([len(XTest0_ATGC)-1,4**k])\n",
    "XTest1KF=np.zeros([len(XTest1_ATGC)-1,4**k])\n",
    "XTest2KF=np.zeros([len(XTest2_ATGC)-1,4**k])\n",
    "\n",
    "ATGC=[XTrain0_ATGC,XTrain1_ATGC,XTrain2_ATGC,XTest0_ATGC,XTest1_ATGC,XTest2_ATGC]\n",
    "KF=[XTrain0KF,XTrain1KF,XTrain2KF,XTest0KF,XTest1KF,XTest2KF]  #KF stands for kernel_features\n",
    "\n",
    "for data in tqdm(range(6)):\n",
    "    for idx,sequence in enumerate(ATGC[data][0][1:]): #[1:] pour ne pas prendre la ligne 'Id,seq'\n",
    "        x = sequence.split(',')[1]\n",
    "        KF[data][idx,:]=phi(x,k,kernel='spectrum_efficient')\n",
    "\n",
    "# Standardize Train features\n",
    "XTrain0KF = StandardScaler(XTrain0KF)\n",
    "XTrain1KF = StandardScaler(XTrain1KF)\n",
    "XTrain2KF = StandardScaler(XTrain2KF)\n",
    "\n",
    "XTest0 = XTest0-XTrain0.mean()/XTrain0.std()\n",
    "XTest1 = XTest1-XTrain1.mean()/XTrain1.std()\n",
    "XTest2 = XTest2-XTrain2.mean()/XTrain2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(K,Y,lmbda=1):\n",
    "    N = K.shape[0]\n",
    "\n",
    "    P = K\n",
    "    G = np.vstack([np.eye(N,N),-np.eye(N,N)])\n",
    "\n",
    "    C = 1/2/N/lmbda\n",
    "    h = np.concatenate([np.repeat(C,N),np.repeat(0,N)])\n",
    "    label = -1.*np.logical_not(Y)+1.*Y\n",
    "    A = np.matrix(Y.astype(np.double))\n",
    "    b = np.zeros(1)\n",
    "    q = -np.ones(N)\n",
    "\n",
    "    P = cvxopt_matrix(P)\n",
    "    G =cvxopt_matrix(G)\n",
    "    h =cvxopt_matrix(h)\n",
    "    b =cvxopt_matrix(b)\n",
    "    A =cvxopt_matrix(A)\n",
    "    q =cvxopt_matrix(q)\n",
    "\n",
    "    sol = cvxopt_solvers.qp(P=P, q=q, G=G, h=h, A=A, b=b, )\n",
    "    alphas = np.array(sol['x'])\n",
    "\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5224e-03 -5.0002e+02  4e+03  4e+00  1e-15\n",
      " 1: -1.3893e-03 -2.7424e+02  3e+02  4e-02  9e-16\n",
      " 2:  3.2634e-03 -3.8699e+00  4e+00  5e-04  1e-15\n",
      " 3:  1.2287e-03 -5.7850e-01  6e-01  8e-05  1e-15\n",
      " 4: -1.0872e-04 -1.4699e-01  2e-01  2e-05  1e-15\n",
      " 5: -3.4707e-03 -7.6645e-03  4e-03  2e-07  1e-15\n",
      " 6: -3.8910e-03 -4.3087e-03  4e-04  1e-08  9e-16\n",
      " 7: -3.9320e-03 -4.0538e-03  1e-04  3e-09  5e-16\n",
      " 8: -3.9456e-03 -3.9705e-03  2e-05  4e-10  6e-16\n",
      " 9: -3.9490e-03 -3.9519e-03  3e-06  2e-16  6e-16\n",
      "10: -3.9493e-03 -3.9494e-03  7e-08  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.4880e-03 -5.0002e+02  4e+03  4e+00  1e-15\n",
      " 1: -1.3756e-03 -2.7424e+02  3e+02  4e-02  1e-15\n",
      " 2:  3.2417e-03 -3.7917e+00  4e+00  5e-04  1e-15\n",
      " 3:  1.5863e-03 -6.8461e-01  7e-01  9e-05  1e-15\n",
      " 4:  1.2879e-03 -1.9624e-01  2e-01  2e-05  4e-15\n",
      " 5: -3.2711e-03 -9.0330e-03  6e-03  2e-07  2e-15\n",
      " 6: -3.8993e-03 -4.2326e-03  3e-04  3e-09  9e-16\n",
      " 7: -3.9389e-03 -3.9872e-03  5e-05  3e-10  5e-16\n",
      " 8: -3.9464e-03 -3.9521e-03  6e-06  3e-11  5e-16\n",
      " 9: -3.9475e-03 -3.9481e-03  6e-07  3e-12  5e-16\n",
      "10: -3.9476e-03 -3.9477e-03  2e-08  4e-14  5e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0913e-03 -5.0004e+02  4e+03  4e+00  1e-15\n",
      " 1: -1.2194e-03 -2.7426e+02  3e+02  4e-02  1e-15\n",
      " 2:  2.8475e-03 -4.6517e+00  5e+00  6e-04  1e-15\n",
      " 3:  1.3911e-03 -7.3309e-01  8e-01  1e-04  1e-15\n",
      " 4:  4.6811e-04 -1.5690e-01  2e-01  2e-05  1e-15\n",
      " 5: -2.8705e-03 -7.3412e-03  5e-03  2e-07  2e-15\n",
      " 6: -3.3552e-03 -3.8270e-03  5e-04  1e-08  9e-16\n",
      " 7: -3.4062e-03 -3.5188e-03  1e-04  2e-09  6e-16\n",
      " 8: -3.4206e-03 -3.4398e-03  2e-05  2e-10  5e-16\n",
      " 9: -3.4234e-03 -3.4256e-03  2e-06  2e-11  5e-16\n",
      "10: -3.4238e-03 -3.4239e-03  6e-08  4e-13  5e-16\n",
      "Optimal solution found.\n",
      "49.33% accuracy on dataset 0\n",
      "50.50% accuracy on dataset 1\n",
      "51.50% accuracy on dataset 2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0372e-03 -5.0042e+00  3e+03  5e+01  9e-16\n",
      " 1: -4.0368e-03 -4.9691e+00  3e+01  5e-01  6e-16\n",
      " 2: -3.2009e-03 -2.7432e+00  3e+00  6e-03  8e-16\n",
      " 3: -1.5978e-03 -4.1955e-01  4e-01  9e-04  9e-16\n",
      " 4: -1.3338e-03 -1.3205e-01  1e-01  2e-04  1e-15\n",
      " 5: -3.5715e-03 -7.1614e-03  4e-03  2e-06  1e-15\n",
      " 6: -3.8968e-03 -4.3053e-03  4e-04  2e-07  8e-16\n",
      " 7: -3.9346e-03 -4.0443e-03  1e-04  5e-08  5e-16\n",
      " 8: -3.9458e-03 -3.9705e-03  2e-05  9e-09  5e-16\n",
      " 9: -3.9490e-03 -3.9515e-03  2e-06  2e-17  6e-16\n",
      "10: -3.9493e-03 -3.9494e-03  6e-08  2e-17  7e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9978e-03 -5.0041e+00  3e+03  5e+01  9e-16\n",
      " 1: -3.9974e-03 -4.9691e+00  3e+01  5e-01  6e-16\n",
      " 2: -3.1674e-03 -2.7424e+00  3e+00  6e-03  7e-16\n",
      " 3: -1.4872e-03 -4.8146e-01  5e-01  1e-03  8e-16\n",
      " 4: -1.5107e-04 -1.7802e-01  2e-01  3e-04  1e-15\n",
      " 5: -3.3819e-03 -8.5284e-03  5e-03  3e-06  1e-15\n",
      " 6: -3.9034e-03 -4.2148e-03  3e-04  7e-08  8e-16\n",
      " 7: -3.9398e-03 -3.9835e-03  4e-05  8e-09  6e-16\n",
      " 8: -3.9466e-03 -3.9515e-03  5e-06  7e-10  5e-16\n",
      " 9: -3.9475e-03 -3.9480e-03  5e-07  5e-11  6e-16\n",
      "10: -3.9476e-03 -3.9477e-03  1e-08  9e-13  5e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5431e-03 -5.0038e+00  3e+03  5e+01  8e-16\n",
      " 1: -3.5427e-03 -4.9687e+00  3e+01  5e-01  6e-16\n",
      " 2: -2.8145e-03 -2.7497e+00  3e+00  7e-03  8e-16\n",
      " 3: -1.3009e-03 -4.4791e-01  5e-01  1e-03  9e-16\n",
      " 4: -9.3815e-04 -1.2371e-01  1e-01  3e-04  1e-15\n",
      " 5: -3.0118e-03 -6.5584e-03  4e-03  3e-06  1e-15\n",
      " 6: -3.3661e-03 -3.7658e-03  4e-04  2e-07  7e-16\n",
      " 7: -3.4083e-03 -3.5098e-03  1e-04  4e-08  5e-16\n",
      " 8: -3.4210e-03 -3.4375e-03  2e-05  4e-09  5e-16\n",
      " 9: -3.4235e-03 -3.4250e-03  1e-06  3e-10  5e-16\n",
      "10: -3.4238e-03 -3.4238e-03  4e-08  5e-12  4e-16\n",
      "Optimal solution found.\n",
      "49.33% accuracy on dataset 0\n",
      "50.50% accuracy on dataset 1\n",
      "51.50% accuracy on dataset 2\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0373e-03 -5.4038e-02  3e+03  5e+01  9e-16\n",
      " 1: -4.0373e-03 -5.4036e-02  3e+01  5e-01  8e-16\n",
      " 2: -4.0372e-03 -5.3767e-02  4e-01  6e-03  7e-16\n",
      " 3: -3.8728e-03 -3.9221e-02  6e-02  6e-04  6e-16\n",
      " 4: -3.4728e-03 -1.7222e-02  2e-02  8e-05  1e-15\n",
      " 5: -3.8491e-03 -4.6854e-03  8e-04  2e-06  7e-16\n",
      " 6: -3.9268e-03 -4.0737e-03  1e-04  4e-07  6e-16\n",
      " 7: -3.9450e-03 -3.9709e-03  3e-05  3e-08  5e-16\n",
      " 8: -3.9490e-03 -3.9515e-03  3e-06  9e-11  6e-16\n",
      " 9: -3.9493e-03 -3.9494e-03  8e-08  2e-12  5e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9979e-03 -5.3999e-02  3e+03  5e+01  9e-16\n",
      " 1: -3.9979e-03 -5.3996e-02  3e+01  5e-01  6e-16\n",
      " 2: -3.9978e-03 -5.3731e-02  4e-01  6e-03  6e-16\n",
      " 3: -3.8230e-03 -3.9666e-02  7e-02  7e-04  6e-16\n",
      " 4: -3.4129e-03 -2.0795e-02  2e-02  1e-04  6e-16\n",
      " 5: -3.8276e-03 -5.0188e-03  1e-03  3e-06  7e-16\n",
      " 6: -3.9308e-03 -4.0432e-03  1e-04  3e-07  6e-16\n",
      " 7: -3.9450e-03 -3.9593e-03  1e-05  2e-08  5e-16\n",
      " 8: -3.9474e-03 -3.9486e-03  1e-06  2e-09  5e-16\n",
      " 9: -3.9476e-03 -3.9477e-03  4e-08  2e-11  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5431e-03 -5.3545e-02  3e+03  5e+01  9e-16\n",
      " 1: -3.5431e-03 -5.3543e-02  3e+01  5e-01  7e-16\n",
      " 2: -3.5427e-03 -5.3263e-02  4e-01  7e-03  6e-16\n",
      " 3: -3.3937e-03 -3.9351e-02  7e-02  7e-04  6e-16\n",
      " 4: -2.9213e-03 -1.8386e-02  2e-02  1e-04  1e-15\n",
      " 5: -3.2862e-03 -4.3684e-03  1e-03  3e-06  9e-16\n",
      " 6: -3.3914e-03 -3.6022e-03  2e-04  6e-07  6e-16\n",
      " 7: -3.4157e-03 -3.4602e-03  4e-05  1e-07  5e-16\n",
      " 8: -3.4225e-03 -3.4286e-03  6e-06  1e-08  5e-16\n",
      " 9: -3.4237e-03 -3.4240e-03  3e-07  1e-10  6e-16\n",
      "10: -3.4238e-03 -3.4238e-03  7e-09  2e-12  5e-16\n",
      "Optimal solution found.\n",
      "49.33% accuracy on dataset 0\n",
      "50.50% accuracy on dataset 1\n",
      "51.50% accuracy on dataset 2\n"
     ]
    }
   ],
   "source": [
    "for lambdaa in [0.001,0.1,10]:\n",
    "\n",
    "    #Load TRAIN data (%split of the labelled dataset)\n",
    "    K0 = np.dot(XTrain0KF[:int(len(XTrain0)*split)],XTrain0KF[:int(len(XTrain0)*split)].T)  \n",
    "    Y0 = np.squeeze(2*YTrain0[:int(len(YTrain0)*split)].to_numpy()-1)\n",
    "\n",
    "    K1 = np.dot(XTrain1KF[:int(len(XTrain1)*split)],XTrain1KF[:int(len(XTrain1)*split)].T)  \n",
    "    Y1 = np.squeeze(2*YTrain1[:int(len(YTrain1)*split)].to_numpy()-1)\n",
    "\n",
    "    K2 = np.dot(XTrain2KF[:int(len(XTrain2)*split)],XTrain2KF[:int(len(XTrain2)*split)].T) \n",
    "    Y2 = np.squeeze(2*YTrain2[:int(len(YTrain2)*split)].to_numpy()-1)\n",
    "\n",
    "    #Predict alphas\n",
    "    alpha0 = SVM(K0,Y0,lambdaa)\n",
    "    alpha1 = SVM(K1,Y1,lambdaa)\n",
    "    alpha2 = SVM(K2,Y2,lambdaa)\n",
    "\n",
    "    #Predictions -1/1 on VALIDATION DATA (%(1-split) of the labelled dataset)\n",
    "    predictions0 = alpha0.T@np.dot(XTrain0KF[:int(len(XTrain0)*split)], XTrain0KF[int(len(XTrain0)*split):].T)\n",
    "    predictions1 = alpha1.T@np.dot(XTrain1KF[:int(len(XTrain0)*split)], XTrain1KF[int(len(XTrain0)*split):].T)\n",
    "    predictions2 = alpha2.T@np.dot(XTrain2KF[:int(len(XTrain0)*split)], XTrain2KF[int(len(XTrain0)*split):].T)\n",
    "\n",
    "    #Predictions 0/1 on VALIDATION DATA (%(1-split) of the labelled dataset)\n",
    "    predictions0 = np.squeeze((1+np.sign(predictions0))/2)\n",
    "    predictions1 = np.squeeze((1+np.sign(predictions1))/2)\n",
    "    predictions2 = np.squeeze((1+np.sign(predictions2))/2)\n",
    "                             \n",
    "    #Asses the predictions\n",
    "    y_true0 = np.array(YTrain0['Bound'][int(len(XTrain0)*split):])\n",
    "    y_true1 = np.array(YTrain1['Bound'][int(len(XTrain0)*split):])\n",
    "    y_true2 = np.array(YTrain2['Bound'][int(len(XTrain0)*split):])\n",
    "\n",
    "    print(\"{:.2f}% accuracy on dataset 0\".format(100*(1-np.mean(abs(y_true0-predictions0)))))\n",
    "    print(\"{:.2f}% accuracy on dataset 1\".format(100*(1-np.mean(abs(y_true1-predictions1)))))\n",
    "    print(\"{:.2f}% accuracy on dataset 2\".format(100*(1-np.mean(abs(y_true2-predictions2)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate csv file to upload on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.9859e+02 -1.0209e+00  9e+03  1e+02  3e-13\n",
      " 1: -1.0367e+01 -1.0208e+00  9e+01  1e+00  3e-13\n",
      " 2: -4.7310e-01 -1.0108e+00  1e+00  7e-03  4e-15\n",
      " 3: -4.3691e-01 -5.7537e-01  1e-01  9e-18  8e-16\n",
      " 4: -4.8040e-01 -5.0202e-01  2e-02  3e-18  2e-15\n",
      " 5: -4.8084e-01 -4.8257e-01  2e-03  2e-18  1e-15\n",
      " 6: -4.8086e-01 -4.8145e-01  6e-04  5e-18  5e-16\n",
      " 7: -4.8098e-01 -4.8106e-01  8e-05  2e-18  1e-15\n",
      " 8: -4.8100e-01 -4.8100e-01  4e-06  1e-17  2e-15\n",
      " 9: -4.8100e-01 -4.8100e-01  4e-08  5e-18  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0002e+03 -1.0005e+00  8e+03  9e+01  3e-13\n",
      " 1: -1.0351e+01 -1.0004e+00  8e+01  9e-01  3e-13\n",
      " 2: -4.5203e-01 -9.9054e-01  1e+00  5e-03  3e-15\n",
      " 3: -4.4945e-01 -5.2947e-01  8e-02  3e-18  5e-16\n",
      " 4: -4.9900e-01 -5.0077e-01  2e-03  3e-18  2e-15\n",
      " 5: -4.9949e-01 -4.9968e-01  2e-04  5e-18  2e-15\n",
      " 6: -4.9950e-01 -4.9950e-01  3e-06  3e-18  2e-15\n",
      " 7: -4.9950e-01 -4.9950e-01  5e-07  2e-18  1e-15\n",
      " 8: -4.9950e-01 -4.9950e-01  2e-07  2e-18  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0002e+03 -1.0020e+00  8e+03  1e+02  3e-13\n",
      " 1: -1.0353e+01 -1.0019e+00  8e+01  9e-01  3e-13\n",
      " 2: -4.5369e-01 -9.9207e-01  1e+00  5e-03  3e-15\n",
      " 3: -4.4857e-01 -5.3296e-01  8e-02  1e-17  5e-16\n",
      " 4: -4.9798e-01 -5.0133e-01  3e-03  1e-17  2e-15\n",
      " 5: -4.9829e-01 -4.9873e-01  4e-04  6e-18  2e-15\n",
      " 6: -4.9846e-01 -4.9854e-01  8e-05  5e-18  1e-15\n",
      " 7: -4.9849e-01 -4.9853e-01  5e-05  1e-17  2e-15\n",
      " 8: -4.9850e-01 -4.9850e-01  5e-06  8e-18  1e-15\n",
      " 9: -4.9850e-01 -4.9850e-01  1e-06  2e-18  2e-15\n",
      "10: -4.9850e-01 -4.9850e-01  6e-08  8e-18  1e-15\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "K0 = np.dot(XTrain0,XTrain0.T)  #linear kernel\n",
    "Y0 = np.squeeze(2*YTrain0.to_numpy()-1)\n",
    "\n",
    "K1 = np.dot(XTrain1,XTrain1.T)   #linear kernel\n",
    "Y1 = np.squeeze(2*YTrain1.to_numpy()-1)\n",
    "\n",
    "K2 = np.dot(XTrain2,XTrain2.T)   #linear kernel\n",
    "Y2 = np.squeeze(2*YTrain2.to_numpy()-1)\n",
    "\n",
    "#Predict alphas\n",
    "alpha0 = SVM(K0,Y0)\n",
    "alpha1 = SVM(K1,Y1)\n",
    "alpha2 = SVM(K2,Y2)\n",
    "\n",
    "#Predictions -1/1\n",
    "predictions0 = alpha0.T@np.dot(XTrain0, XTest0.T)\n",
    "predictions1 = alpha1.T@np.dot(XTrain1, XTest1.T)\n",
    "predictions2 = alpha2.T@np.dot(XTrain2, XTest2.T)\n",
    "\n",
    "#Predictions 0/1\n",
    "predictions0 = (1+np.sign(predictions0))/2\n",
    "predictions1 = (1+np.sign(predictions1))/2\n",
    "predictions2 = (1+np.sign(predictions2))/2\n",
    "\n",
    "# Creation of the Kaggle submission file\n",
    "df0 = pd.DataFrame({'Id': np.arange(1000), 'Bound': predictions0.squeeze().astype(int)})\n",
    "df1 = pd.DataFrame({'Id': np.arange(1000,2000), 'Bound': predictions1.squeeze().astype(int)})\n",
    "df2 = pd.DataFrame({'Id': np.arange(2000,3000), 'Bound': predictions2.squeeze().astype(int)})\n",
    "dfResult = pd.concat([df0,df1,df2])\n",
    "dfResult.to_csv('./data/submissionSVM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
